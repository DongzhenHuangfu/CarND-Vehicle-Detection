{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vehicle detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Wyatt\\Miniconda3\\envs\\carnd-term1\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "C:\\Users\\Wyatt\\Miniconda3\\envs\\carnd-term1\\lib\\site-packages\\sklearn\\grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm, grid_search\n",
    "import time\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import cv2\n",
    "from skimage.feature import hog\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "import pickle\n",
    "from sklearn.externals import joblib \n",
    "from scipy.ndimage.measurements import label\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_undistort(image, img_points, obj_points):\n",
    "    \n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(obj_points, img_points, gray.shape[::-1], None, None)\n",
    "    \n",
    "    return cv2.undistort(image, mtx, dist, None, mtx)\n",
    "\n",
    "## transform the pictures and save it\n",
    "\n",
    "def wrap(img):\n",
    "    src = np.float32([[190,720], [586,455], [696,455], [1130,720]])\n",
    "    dst = np.float32([[240,720], [240,0], [1040,0], [1040, 720]])\n",
    "    M = cv2.getPerspectiveTransform(src, dst)\n",
    "    img_size = (img.shape[1], img.shape[0])\n",
    "    wraped = cv2.warpPerspective(img, M, img_size, flags=cv2.INTER_LINEAR)\n",
    "    return wraped\n",
    "\n",
    "\n",
    "def hls_pip(img, thres_s=(0,255), thres_h = (0,255), thres_l=(0,255)):\n",
    "    image = cv2.cvtColor(img, cv2.COLOR_RGB2HLS)\n",
    "    H = image[:,:,0]\n",
    "    S = image[:,:,2]\n",
    "    L = image[:,:,1]\n",
    "    \n",
    "    binary_output = np.zeros_like(S)\n",
    "    binary_output[((S<thres_s[1]) & (S>thres_s[0]))|((H<thres_h[1]) & (H>thres_h[0]))|((L<thres_l[1]) & (L>thres_l[0]))] = 1\n",
    "    \n",
    "    return binary_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def histogram_find(nwindows=9, margin=100, minpix=50, plot=0, save=0, image=None):\n",
    "    \n",
    "    binary_wraped = image\n",
    "    \n",
    "    # take a histogram of bottom half of the image\n",
    "    histogram = np.sum(binary_wraped[binary_wraped.shape[0]//2:,:], axis=0)\n",
    "    \n",
    "    # generate a picture to visualize the result\n",
    "    out_image = np.dstack((binary_wraped,binary_wraped,binary_wraped))\n",
    "    \n",
    "    # find the peak of the histogram as the starting point\n",
    "    mid_point = (500,780)\n",
    "    leftx_start = np.argmax(histogram[:mid_point[0]])\n",
    "    rightx_start = np.argmax(histogram[mid_point[1]:]) + mid_point[1]\n",
    "    \n",
    "    #set the height of the sliding window\n",
    "    window_height = np.int(histogram.shape[0]//nwindows)\n",
    "    \n",
    "    # find all the nonzero pixels\n",
    "    nonzero = binary_wraped.nonzero()\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "    nonzerox = np.array(nonzero[1])\n",
    "    \n",
    "    # define the current position\n",
    "    leftx_current = leftx_start\n",
    "    rightx_current = rightx_start\n",
    "    \n",
    "    # list to save the left and right positions of pixels in the form of index\n",
    "    left_lane_inds = []\n",
    "    right_lane_inds = []\n",
    "    \n",
    "    # slide the window\n",
    "    for window in range(nwindows):\n",
    "        # define the window boundaries\n",
    "        win_y_low = binary_wraped.shape[0] - (1 + window) * window_height\n",
    "        win_y_high = binary_wraped.shape[0] - window * window_height\n",
    "        win_xleft_low = leftx_current - margin\n",
    "        win_xleft_high = leftx_current + margin\n",
    "        win_xright_low = rightx_current - margin\n",
    "        win_xright_high = rightx_current + margin\n",
    "        \n",
    "        # visualize the window\n",
    "        if plot:\n",
    "            cv2.rectangle(out_image,(win_xleft_low,win_y_low),(win_xleft_high,win_y_high),(0,255,0), 2) \n",
    "            cv2.rectangle(out_image,(win_xright_low,win_y_low),(win_xright_high,win_y_high),(0,255,0), 2)\n",
    "        \n",
    "        # find the nonzero pixel within the window in x and y\n",
    "        good_left_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & (nonzerox >= win_xleft_low) &  (nonzerox < win_xleft_high)).nonzero()[0]\n",
    "        good_right_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & (nonzerox >= win_xright_low) & (nonzerox < win_xright_high)).nonzero()[0]\n",
    "        \n",
    "        # add the index into the list\n",
    "        left_lane_inds.append(good_left_inds)\n",
    "        right_lane_inds.append(good_right_inds)\n",
    "        \n",
    "        # relocate the center of the window if find > minpix pixels\n",
    "        if len(good_left_inds) > minpix:\n",
    "            leftx_current = np.int(np.mean(nonzerox[good_left_inds]))\n",
    "        if len(good_right_inds) > minpix:        \n",
    "            rightx_current = np.int(np.mean(nonzerox[good_right_inds]))\n",
    "            \n",
    "    # Concatenate the arrays of indices\n",
    "    left_lane_inds = np.concatenate(left_lane_inds)\n",
    "    right_lane_inds = np.concatenate(right_lane_inds)\n",
    "\n",
    "    # Extract left and right line pixel positions\n",
    "    leftx = nonzerox[left_lane_inds]\n",
    "    lefty = nonzeroy[left_lane_inds] \n",
    "    rightx = nonzerox[right_lane_inds]\n",
    "    righty = nonzeroy[right_lane_inds] \n",
    "\n",
    "    # Fit a second order polynomial to each\n",
    "    left_fit = np.polyfit(lefty, leftx, 2)\n",
    "    right_fit = np.polyfit(righty, rightx, 2)\n",
    "    \n",
    "    # Visualization\n",
    "    if plot:\n",
    "        ploty = np.linspace(0, binary_wraped.shape[0]-1, binary_wraped.shape[0] )\n",
    "        left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n",
    "        right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]\n",
    "\n",
    "        out_image[nonzeroy[left_lane_inds], nonzerox[left_lane_inds]] = [255, 0, 0]\n",
    "        out_image[nonzeroy[right_lane_inds], nonzerox[right_lane_inds]] = [255, 0, 0]\n",
    "        plt.figure()\n",
    "        plt.imshow(out_image)\n",
    "        plt.plot(left_fitx, ploty, color='yellow')\n",
    "        plt.plot(right_fitx, ploty, color='yellow')\n",
    "        plt.xlim(0, 1280)\n",
    "        plt.ylim(720, 0)\n",
    "        plt.title(figurename, fontsize=50)\n",
    "    \n",
    "    # save the picture\n",
    "    if save:\n",
    "        plt.savefig('./output_images/histogram/'+figurename)\n",
    "    return left_fit, right_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precious_search(left_fit, right_fit,margin=100, plot=0, save=0, image=None):\n",
    "    \n",
    "    binary_wraped = image\n",
    "    nonzero = binary_wraped.nonzero()\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "    nonzerox = np.array(nonzero[1])\n",
    "    \n",
    "    left_lane_inds = ((nonzerox > (left_fit[0] * nonzeroy ** 2 + left_fit[1]*nonzeroy + left_fit[2] - margin)) & \n",
    "                     (nonzerox < (left_fit[0] * nonzeroy ** 2 + left_fit[1]*nonzeroy + left_fit[2] + margin)))\n",
    "    right_lane_inds = ((nonzerox > (right_fit[0] * nonzeroy ** 2 + right_fit[1]*nonzeroy + right_fit[2] - margin)) & \n",
    "                     (nonzerox < (right_fit[0] * nonzeroy ** 2 + right_fit[1]*nonzeroy + right_fit[2] + margin)))\n",
    "    \n",
    "    leftx = nonzerox[left_lane_inds]\n",
    "    rightx = nonzerox[right_lane_inds]\n",
    "    lefty = nonzeroy[left_lane_inds]\n",
    "    righty = nonzeroy[right_lane_inds]\n",
    "    \n",
    "    left_fit = np.polyfit(lefty, leftx, 2)\n",
    "    right_fit = np.polyfit(righty, rightx, 2)\n",
    "    \n",
    "    ploty = np.linspace(0, binary_wraped.shape[0]-1, binary_wraped.shape[0] )\n",
    "    left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n",
    "    right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]\n",
    "    \n",
    "    ## visualization\n",
    "    out_img = np.dstack((binary_wraped, binary_wraped, binary_wraped))\n",
    "    window_img = np.zeros_like(out_img)\n",
    "    \n",
    "    # Color in left and right line pixels\n",
    "    out_img[nonzeroy[left_lane_inds], nonzerox[left_lane_inds]] = [255, 0, 0]\n",
    "    out_img[nonzeroy[right_lane_inds], nonzerox[right_lane_inds]] = [255, 0, 0]\n",
    "\n",
    "    # Generate a polygon to illustrate the search window area\n",
    "    # And recast the x and y points into usable format for cv2.fillPoly()\n",
    "    left_line_window1 = np.array([np.transpose(np.vstack([left_fitx-margin, ploty]))])\n",
    "    left_line_window2 = np.array([np.flipud(np.transpose(np.vstack([left_fitx+margin, \n",
    "                                  ploty])))])\n",
    "    left_line_pts = np.hstack((left_line_window1, left_line_window2))\n",
    "    right_line_window1 = np.array([np.transpose(np.vstack([right_fitx-margin, ploty]))])\n",
    "    right_line_window2 = np.array([np.flipud(np.transpose(np.vstack([right_fitx+margin, \n",
    "                                  ploty])))])\n",
    "    right_line_pts = np.hstack((right_line_window1, right_line_window2))\n",
    "\n",
    "    # Visualization\n",
    "    if plot:\n",
    "        plt.figure()\n",
    "        cv2.fillPoly(window_img, np.int_([left_line_pts]), (0,255, 0))\n",
    "        cv2.fillPoly(window_img, np.int_([right_line_pts]), (0,255, 0))\n",
    "        result = cv2.addWeighted(out_img, 1, window_img, 0.3, 0)\n",
    "        plt.imshow(result)\n",
    "        plt.plot(left_fitx, ploty, color='yellow')\n",
    "        plt.plot(right_fitx, ploty, color='yellow')\n",
    "        plt.xlim(0, 1280)\n",
    "        plt.ylim(720, 0)\n",
    "        plt.title(figurename, fontsize=50)\n",
    "        \n",
    "    if save:\n",
    "        plt.savefig('./output_images/histogram/precious_'+figurename)\n",
    "    \n",
    "    return left_fit, right_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_curv(left_fit, right_fit):\n",
    "    \n",
    "    ym_per_pix = 30/720 # meters per pixel in y dimension\n",
    "    xm_per_pix = 3.7/700 # meters per pixel in x dimension\n",
    "    \n",
    "    # calculate the curvature around the car position(720 pixel)\n",
    "    left_curv = ((1 + (2*left_fit[0]*720*ym_per_pix + left_fit[1])**2)**1.5) / np.absolute(2*left_fit[0])\n",
    "    right_curv = ((1 + (2*right_fit[0]*720*ym_per_pix + right_fit[1])**2)**1.5) / np.absolute(2*right_fit[0])\n",
    "    \n",
    "    return left_curv, right_curv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Line():\n",
    "    def __init__(self, n):\n",
    "        # was the line detected in the last iteration?\n",
    "        self.detected = False\n",
    "        # set of the x values of fitted line over the last n iterations\n",
    "        self.setx = []\n",
    "        # average x values of the fitted line over the last n iterations\n",
    "        self.iter_num = n\n",
    "        self.bestx = None  \n",
    "        # set of polynomial coefficients over the last n iterations\n",
    "        self.set_poly = []\n",
    "        # polynomial coefficients averaged over the last n iterations\n",
    "        self.best_fit = None  \n",
    "        # radius of curvature of the line in some units\n",
    "        self.radius_of_curvature = None \n",
    "        # distance in meters of vehicle center from the line\n",
    "        self.line_base_pos = None \n",
    "        # count the number of frame\n",
    "        self.count = 0\n",
    "        # strings for printing\n",
    "        self.str1 = None\n",
    "        self.str2 = None\n",
    "        \n",
    "    def update(self, fitline, curvature):\n",
    "        self.count += 1\n",
    "        ploty =  np.linspace(720,0, 720)\n",
    "        self.radius_of_curvature = curvature\n",
    "        \n",
    "        if self.detected:\n",
    "            \n",
    "            if self.count <= self.iter_num:\n",
    "                self.setx.append(self.best_fit[0] * ploty ** 2 + self.best_fit[1]*ploty + self.best_fit[2])\n",
    "                self.set_poly.append(fitline)\n",
    "            else:\n",
    "                del self.setx[0]\n",
    "                del self.set_poly[0]\n",
    "                self.setx.append(self.best_fit[0] * ploty ** 2 + self.best_fit[1]*ploty + self.best_fit[2])\n",
    "                self.set_poly.append(fitline)\n",
    "            sumx = 0\n",
    "            for i in range(len(self.setx)):\n",
    "                sumx += self.setx[i]\n",
    "            self.bestx = sumx/len(self.setx)\n",
    "            sumpoly = 0\n",
    "            for i in range(len(self.set_poly)):\n",
    "                sumpoly += self.set_poly[i]\n",
    "            self.best_fit = sumpoly/len(self.set_poly)\n",
    "            \n",
    "            self.line_base_pos = self.bestx[0] - 640\n",
    "            \n",
    "        else:\n",
    "            self.detected = True\n",
    "            self.set_poly.append(fitline)\n",
    "            self.best_fit = fitline\n",
    "            self.bestx = self.best_fit[0] * ploty ** 2 + self.best_fit[1]*ploty + self.best_fit[2]\n",
    "            self.setx.append(self.best_fit[0] * ploty ** 2 + self.best_fit[1]*ploty + self.best_fit[2])\n",
    "            self.line_base_pos = self.bestx[0] - 640"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function to check out wether the new result good or not\n",
    "def check_output(left_fit, right_fit, oldleft = None, oldright = None, first = False):\n",
    "    result = True\n",
    "    ploty =  np.linspace(720,0,720)\n",
    "    left_x = left_fit[0] * ploty ** 2 + left_fit[1]*ploty + left_fit[2]\n",
    "    right_x = right_fit[0] * ploty ** 2 + right_fit[1]*ploty + right_fit[2]\n",
    "    \n",
    "    # checking that the left and right lane line are roughly parallel\n",
    "    fit_diff = [np.abs(left_fit[0] - right_fit[0])/left_fit[0], np.abs(left_fit[1] - right_fit[1])/left_fit[1]]\n",
    "    \n",
    "    if fit_diff[0] > 0.5 or fit_diff[1] > 0.5:\n",
    "        result = False\n",
    "    if not first:\n",
    "        # calculate the difference of polyfit parameters\n",
    "        poly_diff_left = (oldleft.best_fit - left_fit) / oldleft.best_fit\n",
    "        poly_diff_right = (oldright.best_fit - right_fit) / oldright.best_fit\n",
    "        \n",
    "        if not (abs(poly_diff_left)<np.array([0.7,0.5,0.2])).all() or not (abs(poly_diff_right)<np.array([0.7,0.5,0.2])).all():\n",
    "                result = False\n",
    "                \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pro_video(image, Left, Right, img_points, obj_points):\n",
    "    \n",
    "    S_thres = (200,255)\n",
    "    H_thres = (22,24)\n",
    "    L_thres = (170,255)\n",
    "\n",
    "    good = True\n",
    "    src = np.float32([[190,720], [586,455], [696,455], [1130,720]])\n",
    "    dst = np.float32([[240,720], [240,0], [1040,0], [1040, 720]])\n",
    "    Minv = cv2.getPerspectiveTransform(dst, src)\n",
    "    \n",
    "    # undistort the image\n",
    "    undist = cal_undistort(image, img_points, obj_points)\n",
    "    \n",
    "    # pre-process the image and tranform into bird-eye view\n",
    "    binary_output = hls_pip(undist, thres_s=S_thres, thres_h=H_thres,thres_l=L_thres)\n",
    "    image = wrap(binary_output)*255\n",
    "    \n",
    "    # find the lane line\n",
    "    if Left.detected:\n",
    "        left_fit, right_fit = precious_search(Left.best_fit, Right.best_fit, image=image)\n",
    "        if not check_output(left_fit, right_fit, Left, Right):\n",
    "            left_fit, right_fit = histogram_find(image=image)\n",
    "            if not check_output(left_fit, right_fit, Left, Right, first = True):\n",
    "                good = False\n",
    "    else:\n",
    "        left_fit, right_fit = histogram_find(image=image)\n",
    "    \n",
    "    if good:\n",
    "        # calculate the curvate \n",
    "        left_cur, right_cur = cal_curv(left_fit, right_fit)\n",
    "\n",
    "        # update the information in the class\n",
    "        Left.update(left_fit, left_cur)\n",
    "        Right.update(right_fit, right_cur)\n",
    "    \n",
    "    # take the average information in the class\n",
    "    left_fit = Left.best_fit\n",
    "    right_fit = Right.best_fit\n",
    "    \n",
    "    y_array = np.linspace(720,0, 720)\n",
    "    leftx = left_fit[0] * y_array ** 2 + left_fit[1]*y_array + left_fit[2]\n",
    "    rightx = right_fit[0] * y_array ** 2 + right_fit[1]*y_array + right_fit[2]\n",
    "    \n",
    "    # Create an image to draw the lines on\n",
    "    warp_color = np.zeros_like(undist).astype(np.uint8)\n",
    "\n",
    "    # Recast the x and y points into usable format for cv2.fillPoly()\n",
    "    pts_left = np.array([np.transpose(np.vstack([leftx, y_array]))])\n",
    "    pts_right = np.array([np.flipud(np.transpose(np.vstack([rightx, y_array])))])\n",
    "    pts = np.hstack((pts_left, pts_right))\n",
    "\n",
    "    # Draw the lane onto the warped blank image\n",
    "    cv2.fillPoly(warp_color, np.int_([pts]), (0,255, 0))\n",
    "\n",
    "    # Warp the blank back to original image space using inverse perspective matrix (Minv)\n",
    "    newwarp = cv2.warpPerspective(warp_color, Minv, (image.shape[1], image.shape[0])) \n",
    "    \n",
    "    # Combine the result with the original image \n",
    "    result = cv2.addWeighted(undist, 1, newwarp, 0.3, 0)\n",
    "    \n",
    "    # print the curvatue on the image every 5 frame\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    if (Left.count-1) % 5 == 0:\n",
    "        curc = round(0.5*(Left.radius_of_curvature + Right.radius_of_curvature)/1000, 2)\n",
    "        Left.str1 = 'The curvate of the lane line: ' + str(curc) + ' km'\n",
    "\n",
    "        # find the position of the car\n",
    "        right_line_base = rightx[0]\n",
    "        left_line_base = leftx[0]\n",
    "        middle = 640\n",
    "        distance = 0.5 * (Left.line_base_pos + Right.line_base_pos)\n",
    "        distance = round(distance * 3.7/700 * 100, 2)\n",
    "        if distance < 0:\n",
    "            Left.str2 = 'right of the center: ' + str(abs(distance)) + ' cm'\n",
    "        else:\n",
    "            Left.str2 = 'left of the center: ' + str(abs(distance)) + ' cm'\n",
    "            \n",
    "    cv2.putText(result,Left.str1,(400,650), font, 1,(0,0,255),2,cv2.LINE_AA)\n",
    "    cv2.putText(result,Left.str2,(400,700), font, 1,(0,0,255),2,cv2.LINE_AA)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## define a function to find hog features of the images\n",
    "## set vis as true to show the result.\n",
    "\n",
    "def get_hog_features(img, orient, pix_per_cell, cell_per_block, vis=False,\n",
    "                     feature_vec=True):\n",
    "    return_list = hog(img, orientations=orient, pixels_per_cell=(pix_per_cell, pix_per_cell),\n",
    "                                  cells_per_block=(cell_per_block, cell_per_block),\n",
    "                                  block_norm= 'L2-Hys', transform_sqrt=False, \n",
    "                                  visualise= vis, feature_vector= feature_vec)\n",
    "    \n",
    "    # name returns explicitly\n",
    "    if vis:\n",
    "        hog_features = return_list[0]\n",
    "        hog_image = return_list[1]\n",
    "        return hog_features, hog_image\n",
    "    else:\n",
    "        return return_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## combine the features in color space\n",
    "\n",
    "# Define a function to compute binned color features  \n",
    "def bin_spatial(img, size=(32, 32)):\n",
    "    # Use cv2.resize().ravel() to create the feature vector\n",
    "    features = cv2.resize(img, size).ravel() \n",
    "    # Return the feature vector\n",
    "    return features\n",
    "\n",
    "# Define a function to compute color histogram features  \n",
    "def color_hist(img, nbins=32, bins_range=(0, 256)):\n",
    "    # Compute the histogram of the color channels separately\n",
    "    channel1_hist = np.histogram(img[:,:,0], bins=nbins, range=bins_range)\n",
    "    channel2_hist = np.histogram(img[:,:,1], bins=nbins, range=bins_range)\n",
    "    channel3_hist = np.histogram(img[:,:,2], bins=nbins, range=bins_range)\n",
    "    # Concatenate the histograms into a single feature vector\n",
    "    hist_features = np.concatenate((channel1_hist[0], channel2_hist[0], channel3_hist[0]))\n",
    "    # Return the individual histograms, bin_centers and feature vector\n",
    "    return hist_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## combine the features in hog, spatial and in color histogramm\n",
    "\n",
    "def extract_features(imgs, color_space='RGB', spatial_size=(32, 32),\n",
    "                        hist_bins=32, orient=9, \n",
    "                        pix_per_cell=8, cell_per_block=2, hog_channel=0,\n",
    "                        spatial_feat=True, hist_feat=True, hog_feat=True):\n",
    "    # Create a list to append feature vectors to\n",
    "    features = []\n",
    "    # Iterate through the list of images\n",
    "    for image in imgs:\n",
    "        file_features = []\n",
    "        # apply color conversion if other than 'RGB'\n",
    "        if color_space != 'RGB':\n",
    "            string = 'cv2.COLOR_RGB2' + color_space\n",
    "            feature_image = cv2.cvtColor(image, eval(string))\n",
    "        else: feature_image = np.copy(image)      \n",
    "\n",
    "        if spatial_feat == True:\n",
    "            spatial_features = bin_spatial(feature_image, size=spatial_size)\n",
    "            file_features.append(spatial_features)\n",
    "        if hist_feat == True:\n",
    "            # Apply color_hist()\n",
    "            hist_features = color_hist(feature_image, nbins=hist_bins)\n",
    "            file_features.append(hist_features)\n",
    "        if hog_feat == True:\n",
    "        # Call get_hog_features() with vis=False, feature_vec=True\n",
    "            if hog_channel == 'ALL':\n",
    "                hog_features = []\n",
    "                for channel in range(feature_image.shape[2]):\n",
    "                    hog_features.append(get_hog_features(feature_image[:,:,channel], \n",
    "                                        orient, pix_per_cell, cell_per_block, \n",
    "                                        vis=False, feature_vec=True))\n",
    "                hog_features = np.ravel(hog_features)        \n",
    "            else:\n",
    "                hog_features = get_hog_features(feature_image[:,:,hog_channel], orient, \n",
    "                            pix_per_cell, cell_per_block, vis=False, feature_vec=True)\n",
    "            # Append the new feature vector to the features list\n",
    "            file_features.append(hog_features)\n",
    "        features.append(np.concatenate(file_features))\n",
    "    # Return list of feature vectors\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## define a function to draw the boxes on picture for visualizing the sliding windows\n",
    "\n",
    "def draw_boxes(img, bboxes, color=(0, 0, 255), thick=6):\n",
    "    # Make a copy of the image\n",
    "    imcopy = np.copy(img)\n",
    "    # Iterate through the bounding boxes\n",
    "    for bbox in bboxes:\n",
    "        # Draw a rectangle given bbox coordinates\n",
    "        cv2.rectangle(imcopy, bbox[0], bbox[1], color, thick)\n",
    "    # Return the image copy with boxes drawn\n",
    "    return imcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "## function to produce heatmap\n",
    "def add_heat(heatmap, bbox_list):\n",
    "    # Iterate through list of bboxes\n",
    "    for box in bbox_list:\n",
    "        # Add += 1 for all pixels inside each bbox\n",
    "        # Assuming each \"box\" takes the form ((x1, y1), (x2, y2))\n",
    "        heatmap[box[0][1]:box[1][1], box[0][0]:box[1][0]] += 1\n",
    "\n",
    "    # Return updated heatmap\n",
    "    return heatmap# Iterate through list of bboxes\n",
    "    \n",
    "def apply_threshold(heatmap, threshold):\n",
    "    # Zero out pixels below the threshold\n",
    "    heatmap[heatmap <= threshold] = 0\n",
    "    # Return thresholded map\n",
    "    return heatmap\n",
    "\n",
    "def draw_labeled_bboxes(img, labels):\n",
    "    # Iterate through all detected cars\n",
    "    for car_number in range(1, labels[1]+1):\n",
    "        # Find pixels with each car_number label value\n",
    "        nonzero = (labels[0] == car_number).nonzero()\n",
    "        # Identify x and y values of those pixels\n",
    "        nonzeroy = np.array(nonzero[0])\n",
    "        nonzerox = np.array(nonzero[1])\n",
    "        # Define a bounding box based on min/max x and y\n",
    "        bbox = ((np.min(nonzerox), np.min(nonzeroy)), (np.max(nonzerox), np.max(nonzeroy)))\n",
    "        # filt out the wired window\n",
    "        long = np.max(nonzerox) - np.min(nonzerox)\n",
    "        width = np.max(nonzeroy) - np.min(nonzeroy)\n",
    "        if long*1.3 <= width:\n",
    "            continue\n",
    "        # Draw the box on the image\n",
    "        else: cv2.rectangle(img, bbox[0], bbox[1], (0,0,255), 6)\n",
    "    # Return the image\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function that can extract features using sub-sampling and make predictions\n",
    "def find_windows(img, ystart, ystop, scale, svc, X_scaler, orient, pix_per_cell, cell_per_block, spatial_size, hist_bins):\n",
    "    \n",
    "    windows = []\n",
    "    \n",
    "    draw_img = np.copy(img)\n",
    "    img = img.astype(np.float32)/255\n",
    "    \n",
    "    img_tosearch = img[ystart:ystop,:,:]\n",
    "    if scale != 1:\n",
    "        imshape = img_tosearch.shape\n",
    "        img_tosearch = cv2.resize(img_tosearch, (np.int(imshape[1]/scale), np.int(imshape[0]/scale)))\n",
    "\n",
    "    # Define blocks and steps as above\n",
    "    nxblocks = (img_tosearch[:,:,0].shape[1] // pix_per_cell) - cell_per_block + 1\n",
    "    nyblocks = (img_tosearch[:,:,0].shape[0] // pix_per_cell) - cell_per_block + 1 \n",
    "    nfeat_per_block = orient*cell_per_block**2\n",
    "    \n",
    "    # 64 was the orginal sampling rate, with 8 cells and 8 pix per cell\n",
    "    window = 64\n",
    "    nblocks_per_window = (window // pix_per_cell) - cell_per_block + 1\n",
    "    cells_per_step = 2  # Instead of overlap, define how many cells to step\n",
    "    nxsteps = (nxblocks - nblocks_per_window) // cells_per_step + 1\n",
    "    nysteps = (nyblocks - nblocks_per_window) // cells_per_step + 1\n",
    "    \n",
    "    for xb in range(nxsteps):\n",
    "        for yb in range(nysteps):\n",
    "            ypos = yb*cells_per_step\n",
    "            xpos = xb*cells_per_step\n",
    "            xleft = xpos*pix_per_cell\n",
    "            ytop = ypos*pix_per_cell\n",
    "\n",
    "            # Extract the image patch\n",
    "            subimg = cv2.resize(img_tosearch[ytop:ytop+window, xleft:xleft+window], (64,64))\n",
    "          \n",
    "            # Get features\n",
    "            features = extract_features([subimg], color_space='YUV', \n",
    "                        spatial_size=spatial_size, hist_bins=hist_bins, \n",
    "                        orient=orient, pix_per_cell=pix_per_cell, \n",
    "                        cell_per_block=cell_per_block, \n",
    "                        hog_channel='ALL', spatial_feat=True, \n",
    "                        hist_feat=True, hog_feat=True)\n",
    "\n",
    "            # Scale features and make a prediction\n",
    "            test_features = X_scaler.transform(features)    \n",
    "            #test_features = X_scaler.transform(np.hstack((shape_feat, hist_feat)).reshape(1, -1))    \n",
    "            test_prediction = svc.predict(test_features)\n",
    "            \n",
    "            if test_prediction == 1 and svc.decision_function(test_features) >= 0.5:\n",
    "                xbox_left = np.int(xleft*scale)\n",
    "                ytop_draw = np.int(ytop*scale)\n",
    "                win_draw = np.int(window*scale)\n",
    "                windows.append([(xbox_left, ytop_draw+ystart), (xbox_left+win_draw, ytop_draw+win_draw+ystart)]) \n",
    "                \n",
    "    return windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "## define a class to save the last n frames\n",
    "class save_frame():\n",
    "    def __init__(self, n):\n",
    "        self.old_windows = [[] for i in range(n//2)] \n",
    "        self.max_frames = n\n",
    "        \n",
    "    def update_window(self, windows): # update the previous windows and throw some old windows\n",
    "        self.old_windows.append(windows)\n",
    "        if len(self.old_windows) > self.max_frames:\n",
    "            self.old_windows = self.old_windows[len(self.old_windows)-self.max_frames:] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_video_withlines(image):\n",
    "    \n",
    "    global old_frames, Left, Right, clf, X_scaler \n",
    "\n",
    "    ## set parameters\n",
    "    color_space = 'YUV' # Can be RGB, HSV, LUV, HLS, YUV, YCrCb\n",
    "    orient = 11  # HOG orientations\n",
    "    pix_per_cell = 16 # HOG pixels per cell\n",
    "    cell_per_block = 2 # HOG cells per block\n",
    "    hog_channel = 'ALL' # Can be 0, 1, 2, or \"ALL\"\n",
    "    spatial_size = (16, 16) # Spatial binning dimensions\n",
    "    hist_bins = 16    # Number of histogram bins\n",
    "    \n",
    "    windows = []\n",
    "    for scale, ystart, ystop in [(1, 400, 464), (1, 416, 480), (1, 380, 480), (1.2, 375, 495),\n",
    "                                 (1.3, 390, 480), (1.4, 390, 480), (1.5, 400, 496), \n",
    "                                 (1.5, 416, 540), (1.7, 400, 510), (2, 400, 560)]:\n",
    "        out_img = find_windows(image, ystart, ystop, scale, clf, X_scaler, orient, \n",
    "                               pix_per_cell, cell_per_block, spatial_size, hist_bins)\n",
    "        windows.extend(out_img)\n",
    "    \n",
    "    old_frames.update_window(windows)\n",
    "    heat = np.zeros_like(image[:,:,0]).astype(np.float)\n",
    "    heat = add_heat(heat,windows)\n",
    "    for old_frame_windows in old_frames.old_windows:\n",
    "        heat = add_heat(heat,old_frame_windows)\n",
    "    heat = apply_threshold(heat,2*(2+len(old_frames.old_windows)))\n",
    "    heatmap = np.clip(heat, 0, 255)\n",
    "    \n",
    "    labels = label(heatmap)\n",
    "    \n",
    "    ## draw the lines at relevant information on the video\n",
    "    image_to_draw = pro_video(image, Left, Right, img_points, obj_points)\n",
    "    \n",
    "    draw_img = draw_labeled_bboxes(image_to_draw, labels)\n",
    "    \n",
    "    return draw_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "## define the function tp operate on videos\n",
    "\n",
    "def find_video(image):\n",
    "    \n",
    "    global old_frames, clf, X_scaler\n",
    "\n",
    "    ## set parameters\n",
    "    color_space = 'YUV' # Can be RGB, HSV, LUV, HLS, YUV, YCrCb\n",
    "    orient = 11  # HOG orientations\n",
    "    pix_per_cell = 16 # HOG pixels per cell\n",
    "    cell_per_block = 2 # HOG cells per block\n",
    "    hog_channel = 'ALL' # Can be 0, 1, 2, or \"ALL\"\n",
    "    spatial_size = (16, 16) # Spatial binning dimensions\n",
    "    hist_bins = 16    # Number of histogram bins\n",
    "    \n",
    "    windows = []\n",
    "    for scale, ystart, ystop in [(1, 400, 464), (1, 416, 480), (1, 380, 480), (1.2, 375, 495),\n",
    "                                 (1.3, 390, 480), (1.4, 390, 480), (1.5, 400, 496), \n",
    "                                 (1.5, 416, 540), (1.7, 400, 510), (2, 400, 560)]:\n",
    "        out_img = find_windows(image, ystart, ystop, scale, clf, X_scaler, orient,\n",
    "                               pix_per_cell, cell_per_block, spatial_size, hist_bins)\n",
    "        windows.extend(out_img)\n",
    "    \n",
    "    old_frames.update_window(windows)\n",
    "    heat = np.zeros_like(image[:,:,0]).astype(np.float)\n",
    "    for old_frame_windows in old_frames.old_windows:\n",
    "        heat = add_heat(heat,old_frame_windows)\n",
    "    heat = apply_threshold(heat,2*(2+len(old_frames.old_windows)))\n",
    "    heatmap = np.clip(heat, 0, 255)\n",
    "    \n",
    "    labels = label(heatmap)\n",
    "    draw_img = draw_labeled_bboxes(np.copy(image), labels)\n",
    "    \n",
    "    return draw_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Left = Line(5)\n",
    "Right = Line(5)\n",
    "\n",
    "## load the data\n",
    "clf = joblib.load(\"./models/model_YUV.m\")\n",
    "with open('./models/data_YUV.pickle', 'rb') as file:\n",
    "    data_dict = pickle.load(file)\n",
    "    X_scaler = data_dict['X_scaler']\n",
    "\n",
    "with open('calibration.pickle', 'rb') as file:\n",
    "    data_dict = pickle.load(file)\n",
    "img_points = data_dict['img']\n",
    "obj_points = data_dict['obj']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video ./output_videos/test_video.mp4\n",
      "[MoviePy] Writing video ./output_videos/test_video.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|███████████████████████████████████████████████████████████████████████████████▉  | 38/39 [00:25<00:00,  1.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: ./output_videos/test_video.mp4 \n",
      "\n",
      "Wall time: 27.3 s\n"
     ]
    }
   ],
   "source": [
    "old_frames = save_frame(10)\n",
    "myclip = VideoFileClip('test_video.mp4')\n",
    "clip = myclip.fl_image(find_video)\n",
    "%time clip.write_videofile('./output_videos/test_video.mp4', audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"960\" height=\"540\" controls>\n",
       "  <source src=\"output_videos/test_video.mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format('output_videos/test_video.mp4'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video ./output_videos/project_video.mp4\n",
      "[MoviePy] Writing video ./output_videos/project_video.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████▉| 1260/1261 [15:26<00:00,  1.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: ./output_videos/project_video.mp4 \n",
      "\n",
      "Wall time: 15min 27s\n"
     ]
    }
   ],
   "source": [
    "old_frames = save_frame(10)\n",
    "myclip = VideoFileClip('project_video.mp4')\n",
    "clip = myclip.fl_image(find_video)\n",
    "%time clip.write_videofile('./output_videos/project_video.mp4', audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"960\" height=\"540\" controls>\n",
       "  <source src=\"output_videos/project_video.mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format('output_videos/project_video.mp4'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video ./output_videos/test_video_withline.mp4\n",
      "[MoviePy] Writing video ./output_videos/test_video_withline.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|███████████████████████████████████████████████████████████████████████████████▉  | 38/39 [14:12<00:22, 22.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: ./output_videos/test_video_withline.mp4 \n",
      "\n",
      "Wall time: 14min 14s\n"
     ]
    }
   ],
   "source": [
    "old_frames = save_frame(10)\n",
    "myclip = VideoFileClip('test_video.mp4')\n",
    "clip = myclip.fl_image(find_video_withlines)\n",
    "%time clip.write_videofile('./output_videos/test_video_withline.mp4', audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"960\" height=\"540\" controls>\n",
       "  <source src=\"output_videos/test_video_withline.mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format('output_videos/test_video_withline.mp4'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video ./output_videos/project_video_withline.mp4\n",
      "[MoviePy] Writing video ./output_videos/project_video_withline.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                               | 1/1261 [00:21<7:22:00, 21.05s/it]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<timed eval>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m<decorator-gen-176>\u001b[0m in \u001b[0;36mwrite_videofile\u001b[1;34m(self, filename, fps, codec, bitrate, audio, audio_fps, preset, audio_nbytes, audio_codec, audio_bitrate, audio_bufsize, temp_audiofile, rewrite_audio, remove_temp, write_logfile, verbose, threads, ffmpeg_params, progress_bar)\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\carnd-term1\\lib\\site-packages\\moviepy\\decorators.py\u001b[0m in \u001b[0;36mrequires_duration\u001b[1;34m(f, clip, *a, **k)\u001b[0m\n\u001b[0;32m     52\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Attribute 'duration' not set\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclip\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     55\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<decorator-gen-175>\u001b[0m in \u001b[0;36mwrite_videofile\u001b[1;34m(self, filename, fps, codec, bitrate, audio, audio_fps, preset, audio_nbytes, audio_codec, audio_bitrate, audio_bufsize, temp_audiofile, rewrite_audio, remove_temp, write_logfile, verbose, threads, ffmpeg_params, progress_bar)\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\carnd-term1\\lib\\site-packages\\moviepy\\decorators.py\u001b[0m in \u001b[0;36muse_clip_fps_by_default\u001b[1;34m(f, clip, *a, **k)\u001b[0m\n\u001b[0;32m    135\u001b[0m              for (k,v) in k.items()}\n\u001b[0;32m    136\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 137\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclip\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mnew_a\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mnew_kw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<decorator-gen-174>\u001b[0m in \u001b[0;36mwrite_videofile\u001b[1;34m(self, filename, fps, codec, bitrate, audio, audio_fps, preset, audio_nbytes, audio_codec, audio_bitrate, audio_bufsize, temp_audiofile, rewrite_audio, remove_temp, write_logfile, verbose, threads, ffmpeg_params, progress_bar)\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\carnd-term1\\lib\\site-packages\\moviepy\\decorators.py\u001b[0m in \u001b[0;36mconvert_masks_to_RGB\u001b[1;34m(f, clip, *a, **k)\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mclip\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mismask\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[0mclip\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclip\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_RGB\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclip\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m@\u001b[0m\u001b[0mdecorator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecorator\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\carnd-term1\\lib\\site-packages\\moviepy\\video\\VideoClip.py\u001b[0m in \u001b[0;36mwrite_videofile\u001b[1;34m(self, filename, fps, codec, bitrate, audio, audio_fps, preset, audio_nbytes, audio_codec, audio_bitrate, audio_bufsize, temp_audiofile, rewrite_audio, remove_temp, write_logfile, verbose, threads, ffmpeg_params, progress_bar)\u001b[0m\n\u001b[0;32m    324\u001b[0m                            \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mthreads\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mthreads\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    325\u001b[0m                            \u001b[0mffmpeg_params\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mffmpeg_params\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 326\u001b[1;33m                            progress_bar=progress_bar)\n\u001b[0m\u001b[0;32m    327\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    328\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mremove_temp\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mmake_audio\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\carnd-term1\\lib\\site-packages\\moviepy\\video\\io\\ffmpeg_writer.py\u001b[0m in \u001b[0;36mffmpeg_write_video\u001b[1;34m(clip, filename, fps, codec, bitrate, preset, withmask, write_logfile, audiofile, verbose, threads, ffmpeg_params, progress_bar)\u001b[0m\n\u001b[0;32m    216\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    217\u001b[0m         for t,frame in clip.iter_frames(progress_bar=progress_bar, with_times=True,\n\u001b[1;32m--> 218\u001b[1;33m                                         fps=fps, dtype=\"uint8\"):\n\u001b[0m\u001b[0;32m    219\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mwithmask\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    220\u001b[0m                 \u001b[0mmask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m255\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mclip\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_frame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\carnd-term1\\lib\\site-packages\\tqdm\\_tqdm.py\u001b[0m in \u001b[0;36m__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    938\u001b[0m \"\"\", fp_write=getattr(self.fp, 'write', sys.stderr.write))\n\u001b[0;32m    939\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 940\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    941\u001b[0m                 \u001b[1;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    942\u001b[0m                 \u001b[1;31m# Update and possibly print the progressbar.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\carnd-term1\\lib\\site-packages\\moviepy\\Clip.py\u001b[0m in \u001b[0;36mgenerator\u001b[1;34m()\u001b[0m\n\u001b[0;32m    473\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    474\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mduration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1.0\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mfps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 475\u001b[1;33m                 \u001b[0mframe\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_frame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    476\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    477\u001b[0m                     \u001b[0mframe\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mframe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<decorator-gen-135>\u001b[0m in \u001b[0;36mget_frame\u001b[1;34m(self, t)\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\carnd-term1\\lib\\site-packages\\moviepy\\decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(f, *a, **kw)\u001b[0m\n\u001b[0;32m     87\u001b[0m         new_kw = {k: fun(v) if k in varnames else v\n\u001b[0;32m     88\u001b[0m                  for (k,v) in kw.items()}\n\u001b[1;32m---> 89\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mnew_a\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mnew_kw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     90\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdecorator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecorator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwrapper\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\carnd-term1\\lib\\site-packages\\moviepy\\Clip.py\u001b[0m in \u001b[0;36mget_frame\u001b[1;34m(self, t)\u001b[0m\n\u001b[0;32m     92\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mframe\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 94\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_frame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     95\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfun\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mapply_to\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeep_duration\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\carnd-term1\\lib\\site-packages\\moviepy\\Clip.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m    135\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    136\u001b[0m         \u001b[1;31m#mf = copy(self.make_frame)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 137\u001b[1;33m         \u001b[0mnewclip\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_make_frame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mfun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_frame\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    138\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    139\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mkeep_duration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\carnd-term1\\lib\\site-packages\\moviepy\\video\\VideoClip.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(gf, t)\u001b[0m\n\u001b[0;32m    504\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mapply_to\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    505\u001b[0m             \u001b[0mapply_to\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 506\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mgf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mimage_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mapply_to\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    507\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    508\u001b[0m     \u001b[1;31m# --------------------------------------------------------------\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-20-6879ffaaf1ef>\u001b[0m in \u001b[0;36mfind_video_withlines\u001b[1;34m(image)\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m     \u001b[1;31m## draw the lines at relevant information on the video\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m     \u001b[0mimage_to_draw\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpro_video\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mLeft\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mRight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg_points\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj_points\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m     \u001b[0mdraw_img\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdraw_labeled_bboxes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_to_draw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-12-b6ec9486a510>\u001b[0m in \u001b[0;36mpro_video\u001b[1;34m(image, Left, Right, img_points, obj_points)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[1;31m# undistort the image\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m     \u001b[0mundist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcal_undistort\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg_points\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj_points\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[1;31m# pre-process the image and tranform into bird-eye view\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-6-d46f6d951ab8>\u001b[0m in \u001b[0;36mcal_undistort\u001b[1;34m(image, img_points, obj_points)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mgray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCOLOR_BGR2GRAY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mret\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmtx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrvecs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtvecs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcalibrateCamera\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj_points\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg_points\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mundistort\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmtx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmtx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "old_frames = save_frame(10)\n",
    "myclip = VideoFileClip('project_video.mp4')\n",
    "clip = myclip.fl_image(find_video_withlines)\n",
    "%time clip.write_videofile('./output_videos/project_video_withline.mp4', audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"960\" height=\"540\" controls>\n",
       "  <source src=\"output_videos/project_video_withline.mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format('output_videos/project_video_withline.mp4'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_video_withlines(image):\n",
    "    \n",
    "    global old_frames, clf, X_scaler, windows_for_draw\n",
    "\n",
    "    ## set parameters\n",
    "    color_space = 'YUV' # Can be RGB, HSV, LUV, HLS, YUV, YCrCb\n",
    "    orient = 11  # HOG orientations\n",
    "    pix_per_cell = 16 # HOG pixels per cell\n",
    "    cell_per_block = 2 # HOG cells per block\n",
    "    hog_channel = 'ALL' # Can be 0, 1, 2, or \"ALL\"\n",
    "    spatial_size = (16, 16) # Spatial binning dimensions\n",
    "    hist_bins = 16    # Number of histogram bins\n",
    "    \n",
    "    windows = []\n",
    "    for scale, ystart, ystop in [(1, 400, 464), (1, 416, 480), (1, 380, 480), (1.2, 375, 495),\n",
    "                                 (1.3, 390, 480), (1.4, 390, 480), (1.5, 400, 496), \n",
    "                                 (1.5, 416, 540), (1.7, 400, 510), (2, 400, 560)]:\n",
    "        out_img = find_windows(image, ystart, ystop, scale, clf, X_scaler, orient,\n",
    "                               pix_per_cell, cell_per_block, spatial_size, hist_bins)\n",
    "        windows.extend(out_img)\n",
    "    \n",
    "    old_frames.update_window(windows)\n",
    "    heat = np.zeros_like(image[:,:,0]).astype(np.float)\n",
    "    for old_frame_windows in old_frames.old_windows:\n",
    "        heat = add_heat(heat,old_frame_windows)\n",
    "    heat = apply_threshold(heat,2*(2+len(old_frames.old_windows)))\n",
    "    heatmap = np.clip(heat, 0, 255)\n",
    "    \n",
    "    labels = label(heatmap)\n",
    "    \n",
    "    temp_windows = []\n",
    "    \n",
    "    for car_number in range(1, labels[1]+1):\n",
    "        # Find pixels with each car_number label value\n",
    "        nonzero = (labels[0] == car_number).nonzero()\n",
    "        # Identify x and y values of those pixels\n",
    "        nonzeroy = np.array(nonzero[0])\n",
    "        nonzerox = np.array(nonzero[1])\n",
    "        # Define a bounding box based on min/max x and y\n",
    "        bbox = ((np.min(nonzerox), np.min(nonzeroy)), (np.max(nonzerox), np.max(nonzeroy)))\n",
    "        # filt out the wired window\n",
    "        long = np.max(nonzerox) - np.min(nonzerox)\n",
    "        width = np.max(nonzeroy) - np.min(nonzeroy)\n",
    "        if long*1.3 <= width:\n",
    "            continue\n",
    "        # Draw the box on the image\n",
    "        else: temp_windows.append((bbox[0], bbox[1]))\n",
    "    \n",
    "    windows_for_draw.append(temp_windows)\n",
    "    \n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video ./output_videos/template.mp4\n",
      "[MoviePy] Writing video ./output_videos/template.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████▉| 1260/1261 [41:24<00:01,  1.97s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: ./output_videos/template.mp4 \n",
      "\n",
      "Wall time: 41min 26s\n"
     ]
    }
   ],
   "source": [
    "windows_for_draw = []\n",
    "old_frames = save_frame(10)\n",
    "myclip = VideoFileClip('project_video.mp4')\n",
    "clip = myclip.fl_image(output_video_withlines)\n",
    "%time clip.write_videofile('./output_videos/template.mp4', audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"960\" height=\"540\" controls>\n",
       "  <source src=\"output_videos/template.mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format('output_videos/template.mp4'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_all_together(image):\n",
    "    global index\n",
    "    \n",
    "    for bboxs in windows_for_draw[index]:\n",
    "        cv2.rectangle(image, bboxs[0], bboxs[1], (0,0,255), 6)\n",
    "    index += 1\n",
    "    \n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'windows_for_draw': windows_for_draw}\n",
    "with open('boxs_data.pickle', 'wb') as file:\n",
    "    pickle.dump(data,file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video ./output_videos/project_video_withline.mp4\n",
      "[MoviePy] Writing video ./output_videos/project_video_withline.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████▉| 1260/1261 [01:21<00:00, 15.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: ./output_videos/project_video_withline.mp4 \n",
      "\n",
      "Wall time: 1min 23s\n"
     ]
    }
   ],
   "source": [
    "index = 0\n",
    "with open('boxs_data.pickle', 'rb') as file:\n",
    "    data = pickle.load(file)\n",
    "    windows_for_draw = data['windows_for_draw']\n",
    "myclip = VideoFileClip('video_from_advanced.mp4')\n",
    "clip = myclip.fl_image(draw_all_together)\n",
    "%time clip.write_videofile('./output_videos/project_video_withline.mp4', audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"960\" height=\"540\" controls>\n",
       "  <source src=\"output_videos/project_video_withline.mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format('output_videos/project_video_withline.mp4'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
